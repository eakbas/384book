{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lk02zqoTukUU"
   },
   "source": [
    "# Training a CNN model on MNIST using PyTorch\n",
    "\n",
    "Sample MNIST images:\n",
    "\n",
    "![MNIST examples](https://www.researchgate.net/profile/Stefan_Elfwing/publication/266205382/figure/fig5/AS:267913563209738@1440886979379/Example-images-of-the-ten-handwritten-digits-in-the-MNIST-training-set.png)\n",
    "\n",
    "- 10 classes\n",
    "- 60 thousand training images\n",
    "- 10 thousand testing images\n",
    "- Each image is monochrome, 28-by-28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGU6NwlsXFSt"
   },
   "outputs": [],
   "source": [
    "#@title Import the required modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHPpr_Xb0fMa"
   },
   "outputs": [],
   "source": [
    "# Define the \"device\". If GPU is available, device is set to use it, otherwise CPU will be used.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lCsBCXMwbpH5"
   },
   "outputs": [],
   "source": [
    "#@title Download the dataset\n",
    "train_data = datasets.MNIST(root = './data', train = True,\n",
    "                        transform = transforms.ToTensor(), download = True)\n",
    "\n",
    "test_data = datasets.MNIST(root = './data', train = False,\n",
    "                       transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3cSd656CSZA"
   },
   "outputs": [],
   "source": [
    "# About the ToTensor() transformation.\n",
    "\n",
    "# PyTorch networks expect a tensor as input with dimensions N*C*H*W  where\n",
    "# N: batch size\n",
    "# C: channel size\n",
    "# H: height\n",
    "# W: width\n",
    "\n",
    "# Normally an image is of size H*W*C.\n",
    "# ToTensor() transformation moves the channel dimension to the beginning as needed by PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfDPBdnYgfGp"
   },
   "outputs": [],
   "source": [
    "#@title Define the data loaders\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data,\n",
    "                                             batch_size = batch_size,\n",
    "                                             shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset =  test_data ,\n",
    "                                      batch_size = batch_size,\n",
    "                                      shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fL-YXTvghaz_"
   },
   "outputs": [],
   "source": [
    "#@title Define a CNN network\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    #This defines the structure of the NN.\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=28, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.view(-1, 10)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create an instance\n",
    "net = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMYUNXAP5p04",
    "outputId": "e0ef8908-b5e4-494e-f3eb-56fd05617646"
   },
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ePLIwvAFj2zH"
   },
   "outputs": [],
   "source": [
    "#@title Define the loss function and the optimizer\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD( net.parameters(), lr=1.e-3)\n",
    "optimizer = torch.optim.SGD( net.parameters(), lr=0.001, momentum=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u75Xa5VckuTH",
    "outputId": "1b847f06-58a5-4807-99cc-fb66e23bb392"
   },
   "outputs": [],
   "source": [
    "#@title Train the model\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "  for i ,(images,labels) in enumerate(train_loader):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    #labels = labels[:,None].float()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = net(images)\n",
    "    loss = loss_fun(output, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (i+1) % batch_size == 0:\n",
    "      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_data)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DTPvMW5jHB9X",
    "outputId": "2b2545c1-01a9-4bf2-815b-acbfb8af14f1"
   },
   "outputs": [],
   "source": [
    "#@title Run the trained model on the testing set\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader:\n",
    "  images = images.to(device)\n",
    "  labels = labels.to(device)\n",
    "\n",
    "  out = net(images)\n",
    "  _, predicted_labels = torch.max(out,1)\n",
    "  correct += (predicted_labels == labels).sum()\n",
    "  total += labels.size(0)\n",
    "\n",
    "print('Percent correct: %.3f %%' %((100*correct)/(total+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lui82pT2V8oK"
   },
   "outputs": [],
   "source": [
    "weights = net.conv1.weight.data.clone().cpu().numpy()#  .features[1].weight.data.clone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1cJc2PUpWS_2",
    "outputId": "640f4e94-6b10-41f1-ad91-08303a8d08aa"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "for i in range(10):\n",
    "  filter = weights[i,:,:,:].reshape(28,28)\n",
    "  plt.figure(i, figsize=(1,1))\n",
    "  plt.imshow(filter, cmap='gray')\n",
    "  im = Image.fromarray(filter, \"L\")\n",
    "  im.save(\"file%d.png\" % i)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
