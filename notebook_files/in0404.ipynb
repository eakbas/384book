{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lk02zqoTukUU"
   },
   "source": [
    "# An application of convolution in machine learning\n",
    "\n",
    "\n",
    "Convolution and cross-correlation operations play a crucial role in computer\n",
    "vision and machine learning, particularly in tasks like visual recognition. Let\n",
    "us delve into a practical application of convolution in hand-written digit\n",
    "recognition.\n",
    "\n",
    "For this, we will use the MNIST dataset. Here are important details about this\n",
    "dataset: \n",
    "\n",
    "- 10 classes, \n",
    "- 60 thousand training images, \n",
    "- 10 thousand testing images, \n",
    "- Each image is monochrome, 28-by-28 pixels.\n",
    "\n",
    "\n",
    "Sample MNIST images:\n",
    "\n",
    "![MNIST examples](https://www.researchgate.net/profile/Stefan_Elfwing/publication/266205382/figure/fig5/AS:267913563209738@1440886979379/Example-images-of-the-ten-handwritten-digits-in-the-MNIST-training-set.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the PyTorch library, which will take care of the optimization,\n",
    "auto-differentiation, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11217,
     "status": "ok",
     "timestamp": 1708603814440,
     "user": {
      "displayName": "Emre Akbas",
      "userId": "16325111650203864576"
     },
     "user_tz": -180
    },
    "id": "bGU6NwlsXFSt"
   },
   "outputs": [],
   "source": [
    "#@title Import the required modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1708603814441,
     "user": {
      "displayName": "Emre Akbas",
      "userId": "16325111650203864576"
     },
     "user_tz": -180
    },
    "id": "wHPpr_Xb0fMa"
   },
   "outputs": [],
   "source": [
    "# Define the \"device\". If GPU is available, device is set to use it, otherwise CPU will be used.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will download the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2918,
     "status": "ok",
     "timestamp": 1708603817332,
     "user": {
      "displayName": "Emre Akbas",
      "userId": "16325111650203864576"
     },
     "user_tz": -180
    },
    "id": "lCsBCXMwbpH5",
    "outputId": "78a93271-fa63-45a5-8a4b-c347e53d8d65"
   },
   "outputs": [],
   "source": [
    "#@title Download the dataset\n",
    "train_data = datasets.MNIST(root = './data', train = True,\n",
    "                        transform = transforms.ToTensor(), download = True)\n",
    "\n",
    "test_data = datasets.MNIST(root = './data', train = False,\n",
    "                       transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we describe in Section 4.3 of the book, here we are only interested in binary\n",
    "classification, that is, we deal with only two classes. We pick \"3\" as the\n",
    "positive (target) class and all remanining digits as the negative class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1708603817332,
     "user": {
      "displayName": "Emre Akbas",
      "userId": "16325111650203864576"
     },
     "user_tz": -180
    },
    "id": "FkfEB70ciZrf"
   },
   "outputs": [],
   "source": [
    "target_class = 3\n",
    "\n",
    "train_data.targets[train_data.targets!=target_class] = 0\n",
    "train_data.targets[train_data.targets==target_class] = 1\n",
    "\n",
    "test_data.targets[test_data.targets!=target_class] = 0\n",
    "test_data.targets[test_data.targets==target_class] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1708603817332,
     "user": {
      "displayName": "Emre Akbas",
      "userId": "16325111650203864576"
     },
     "user_tz": -180
    },
    "id": "n3cSd656CSZA"
   },
   "outputs": [],
   "source": [
    "# About the ToTensor() transformation.\n",
    "\n",
    "# PyTorch networks expect a tensor as input with dimensions N*C*H*W  where\n",
    "# N: batch size\n",
    "# C: channel size\n",
    "# H: height\n",
    "# W: width\n",
    "\n",
    "# Normally an image is of size H*W*C.\n",
    "# ToTensor() transformation moves the channel dimension to the beginning as needed by PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the data loaders. This takes care of shuffling and splitting the\n",
    "dataset into mini-batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1708603817332,
     "user": {
      "displayName": "Emre Akbas",
      "userId": "16325111650203864576"
     },
     "user_tz": -180
    },
    "id": "rfDPBdnYgfGp"
   },
   "outputs": [],
   "source": [
    "#@title Define the data loaders\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_data,\n",
    "                                             batch_size = batch_size,\n",
    "                                             shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset =  test_data ,\n",
    "                                      batch_size = batch_size,\n",
    "                                      shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following piece of code defines our neural network. It consists of a single\n",
    "\"conv\" layer, which essentially implements the cross-correlation operation. Its\n",
    "kernel (filter) size is 28x28, so, its weigths fully covers the input image. We\n",
    "are interested in computing: \n",
    "\n",
    "$$\n",
    "z = (x \\star h)[0,0]\n",
    "$$\n",
    "\n",
    "where x is the input image and h represent the weights of the \"conv\" layer. The\n",
    "output of this layer is then passed through a sigmoid layer: \n",
    "\n",
    "$$\n",
    "\\hat{y} = \\frac{1}{1+e^{z}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1708603817332,
     "user": {
      "displayName": "Emre Akbas",
      "userId": "16325111650203864576"
     },
     "user_tz": -180
    },
    "id": "fL-YXTvghaz_"
   },
   "outputs": [],
   "source": [
    "#@title Define a CNN network\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    #This defines the structure of the NN.\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 1, kernel_size=28, bias=False)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.sig(x.view(-1, 1))\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create an instance\n",
    "net = CNN().to(device)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the loss function and the optimization method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1708603817332,
     "user": {
      "displayName": "Emre Akbas",
      "userId": "16325111650203864576"
     },
     "user_tz": -180
    },
    "id": "ePLIwvAFj2zH"
   },
   "outputs": [],
   "source": [
    "#@title Define the loss function and the optimizer\n",
    "loss_fun = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD( net.parameters(), lr=0.001, momentum=.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following piece of code trains the network (i.e. the \"conv\" layer). There\n",
    "are two loops; the first of which passes through the whole dataset, the second\n",
    "passes through the mini-batches. For each mini-batch, we run the model using its\n",
    "current weights, compute loss, compute the gradient vector of the weights of the\n",
    "conv layer and then update them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76533,
     "status": "ok",
     "timestamp": 1708603893862,
     "user": {
      "displayName": "Emre Akbas",
      "userId": "16325111650203864576"
     },
     "user_tz": -180
    },
    "id": "u75Xa5VckuTH",
    "outputId": "f79499b2-a9ab-4853-9cec-775820dd4779"
   },
   "outputs": [],
   "source": [
    "#@title Train the model\n",
    "losses = []\n",
    "iter_nums = []\n",
    "num_epochs = 7\n",
    "for epoch in range(num_epochs):\n",
    "  for i ,(images,labels) in enumerate(train_loader):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    labels = labels[:,None].float()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = net(images) # runs the model \n",
    "    loss = loss_fun(output, labels)  # computes loss  \n",
    "    loss.backward()  # computes the gradient of the weights \n",
    "    optimizer.step()  # update weights (backpropagation) \n",
    "\n",
    "    # if epoch==4:\n",
    "    #   optimizer = torch.optim.SGD( net.parameters(), lr=0.0001, momentum=.9)\n",
    "\n",
    "    if (i+1) % batch_size == 0:\n",
    "      losses.append(loss.item())\n",
    "      iter_nums.append(epoch*len(train_loader)+i)\n",
    "      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_data)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots the loss over iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 429,
     "status": "ok",
     "timestamp": 1708603908687,
     "user": {
      "displayName": "Emre Akbas",
      "userId": "16325111650203864576"
     },
     "user_tz": -180
    },
    "id": "wByYPbMQk0Bh",
    "outputId": "feedca8d-3359-47fa-f550-fea3abbfed81"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(iter_nums,losses)\n",
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the trained model, we run it on the test set and report percent\n",
    "accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1616,
     "status": "ok",
     "timestamp": 1708603911535,
     "user": {
      "displayName": "Emre Akbas",
      "userId": "16325111650203864576"
     },
     "user_tz": -180
    },
    "id": "DTPvMW5jHB9X",
    "outputId": "949cadb6-7353-4309-bfe6-09c076af62d5"
   },
   "outputs": [],
   "source": [
    "#@title Run the trained model on the testing set\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_loader:\n",
    "  images = images.to(device)\n",
    "  labels = labels.to(device)\n",
    "\n",
    "  out = net(images)\n",
    "  _, predicted_labels = torch.max(out,1)\n",
    "  correct += (predicted_labels == labels).sum()\n",
    "  total += labels.size(0)\n",
    "\n",
    "print('Percent correct: %.3f %%' %((100*correct)/(total+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now plot the learned weights. This should look like the positive class\n",
    "(whcih is \"3\" in our example). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 148
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1708604073461,
     "user": {
      "displayName": "Emre Akbas",
      "userId": "16325111650203864576"
     },
     "user_tz": -180
    },
    "id": "1cJc2PUpWS_2",
    "outputId": "77c9b49a-d2cd-42dd-82cb-5ddf44bf9446"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "weights = net.conv1.weight.data.clone().cpu().numpy()\n",
    "filter = weights.reshape(28,28)\n",
    "plt.figure(i, figsize=(1.2,1.2))\n",
    "plt.axis('off')\n",
    "plt.imshow(filter, cmap='gray')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the multiclass version of this exercise: [click here](in0405). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Related content: \n",
    "\n",
    "[Explore convolution.](in0401)\n",
    "\n",
    "[Explore convolution of two exponential functions.](in0402)\n",
    "\n",
    "[Explore cross-correlation and auto-correlation.](in0403)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1nvdn3N46sT6xBEbPQuyNK8OV3M9DthWz",
     "timestamp": 1570522331444
    },
    {
     "file_id": "https://github.com/AvivSham/Pytorch-MNIST-colab/blob/master/Pytorch_MNIST.ipynb",
     "timestamp": 1570292427967
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
